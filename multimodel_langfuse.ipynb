{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.error import URLError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get local data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: puton.jpg\n",
      "Successfully downloaded: joke_prompt.wav\n",
      "Successfully downloaded: bitcoin.pdf\n"
     ]
    }
   ],
   "source": [
    "REPO_URL = \"https://github.com/langfuse/langfuse-python\"\n",
    "download_path = \"static\"\n",
    "os.makedirs(download_path, exist_ok=True)\n",
    "\n",
    "test_files = [\"puton.jpg\", \"joke_prompt.wav\", \"bitcoin.pdf\"]\n",
    "raw_url = f\"{REPO_URL}/raw/main/{download_path}\"\n",
    "\n",
    "for file in test_files:\n",
    "   try:\n",
    "       urlretrieve(f\"{raw_url}/{file}\", f\"{download_path}/{file}\")\n",
    "       print(f\"Successfully downloaded: {file}\")\n",
    "   except URLError as e:\n",
    "       print(f\"Failed to download {file}: {e}\")\n",
    "   except OSError as e:\n",
    "       print(f\"Failed to save {file}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langfuse Multimodel logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.openai import openai\n",
    "import base64\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "def encode_file(image_path):\n",
    "    with open(image_path, \"rb\") as file:\n",
    "        return base64.b64encode(file.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-BCpI7SJtTx2zNENjpoK2jE1267Iwy', 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The image features a dog with curly fur, sitting with its front paws resting on a person's knee. The dog appears happy, with its tongue out. In the background, there are a few people standing, and the setting seems to be a cozy indoor space with wooden floors and a colorful rug.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], 'created': 1742396799, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'service_tier': 'default', 'system_fingerprint': 'fp_3267753c5d', 'usage': CompletionUsage(completion_tokens=60, prompt_tokens=25514, total_tokens=25574, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=24704)), '_request_id': 'req_5f6f60fdca83030b6977b37449d553ae'}\n"
     ]
    }
   ],
   "source": [
    "content_path = \"static/puton.jpg\"\n",
    "content_type = \"image/jpeg\"\n",
    "\n",
    "base64_image = encode_file(content_path)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Whatâ€™s in this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:{content_type};base64,{base64_image}\"\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.__dict__)\n",
    "\n",
    "openai.flush_langfuse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-BCpEqboDIXVQocT4w89nQWq6bb7uP', 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=ChatCompletionAudio(id='audio_67dadcb667e88190b781cebbc1ef8cb1', data=<langfuse.media.LangfuseMedia object at 0x1281d3770>, expires_at=1742400198, transcript=\"Why don't they play hide and seek in Berlin? Because no matter how good you are at hiding, the Berlin Wall always seems to give people away!\"), function_call=None, tool_calls=None))], 'created': 1742396596, 'model': 'gpt-4o-audio-preview-2024-12-17', 'object': 'chat.completion', 'service_tier': 'default', 'system_fingerprint': 'fp_31e26c9138', 'usage': CompletionUsage(completion_tokens=240, prompt_tokens=66, total_tokens=306, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=196, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=44), prompt_tokens_details=PromptTokensDetails(audio_tokens=49, cached_tokens=0, text_tokens=17, image_tokens=0)), '_request_id': 'req_fb07af635221b5ce46469ae7eb19169e'}\n"
     ]
    }
   ],
   "source": [
    "content_path = \"static/joke_prompt.wav\"\n",
    "\n",
    "base64_string = encode_file(content_path)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-audio-preview\",\n",
    "    modalities=[\"text\", \"audio\"],\n",
    "    audio={\"voice\": \"alloy\", \"format\": \"wav\"},\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Do what this recording says.\"},\n",
    "                {\n",
    "                    \"type\": \"input_audio\",\n",
    "                    \"input_audio\": {\"data\": base64_string, \"format\": \"wav\"},\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.__dict__)\n",
    "\n",
    "openai.flush_langfuse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
